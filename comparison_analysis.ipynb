{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from colorama import Fore\n",
    "import gc\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import math\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "source_df = pd.read_csv( \"ALL.csv.gz\", compression='gzip' )\n",
    "source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info \n",
    "#ana_df = source_df.drop([\"create_timestamp_utc\",\"HR\",\"HUM\",\"PM25\",\"TEM\",\"intercept\"],axis=1)\n",
    "ana_df = source_df.drop([\"training_AirBoxs\",\"training_EPA\"],axis=1)\n",
    "\n",
    "site_list = list( ana_df[\"site\"].unique() )\n",
    "method_list = list( ana_df[\"method\"].unique() )\n",
    "feature_list = list( ana_df[\"feature\"].unique() )\n",
    "day_list = list( ana_df[\"day\"].unique() )\n",
    "earliest = ana_df.date.min()\n",
    "latest = ana_df.date.max()\n",
    "ana_df[\"date_datetime\"] = pd.to_datetime( ana_df[\"date\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "print( \"{green}**site list:\\n{reset}{site}\\n\\n\"\n",
    "      \"{green}**method list:\\n{reset}{method}\\n\\n\"\n",
    "      \"{green}**feature list:\\n{reset}{feature}\\n\\n\"\n",
    "      \"{green}**day list:\\n{reset}{day}\\n\\n\"\n",
    "      \"{green}**time period:\\n{reset}{earliest} - {latest}\\n\\n\"\n",
    "      .format( green=Fore.GREEN, reset=Fore.RESET, site=site_list, \n",
    "              method=method_list, feature=feature_list, day=day_list, \n",
    "             earliest = earliest, latest = latest) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All sites during the whole time period\n",
    "the best Train_R2 of each site everyday\n",
    "\n",
    "1. Line chart, daily\n",
    "2. bar polar animation, daily\n",
    "3. bar polar animation, monthly (Train_R2 mean)\n",
    "\n",
    "---\n",
    "\n",
    "useful dataframe\n",
    "- all_best_df: everyday's best Train_R2 of each site with whole columns\n",
    "- all_best_df_monthly: monthly mean of each site with \"RMSE\", \"Train_R2\", \"Test_R2\"\n",
    "\n",
    "Just a overview :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best result of all time/site\n",
    "def find_best( all_best_df, element=\"Train_R2\" ):\n",
    "    df = all_best_df.iloc[all_best_df.groupby(['date','site']).apply(lambda x: x[element].idxmax())]\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def add_trace_site( site_df, site_name ):\n",
    "    fig_ALL.add_trace( go.Scatter( x=list(site_df.date),\n",
    "                               y=list(site_df.Train_R2),\n",
    "                               name=site_name\n",
    "                             ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_best_df = find_best(ana_df).set_index(keys=['date', 'site'] )\n",
    "all_best_df = find_best(ana_df)\n",
    "all_best_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best_df_monthly = all_best_df.drop( [\"day\", \"feature\", \"method\", \"num\"], axis=1 )\n",
    "\n",
    "all_best_df_monthly = all_best_df_monthly.groupby( [\"site\", \"date_datetime\"] ).mean()\n",
    "\n",
    "level_values = all_best_df_monthly.index.get_level_values\n",
    "all_best_df_monthly = (all_best_df_monthly.groupby([level_values(i) for i in [0]]\n",
    "                      +[pd.Grouper(freq='M', level=-1)]).mean())\n",
    "all_best_df_monthly.reset_index(inplace=True)\n",
    "all_best_df_monthly['month'] = all_best_df_monthly.date_datetime.map( lambda x: x.strftime(\"%Y-%m\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig_ALL = go.Figure()\n",
    "\n",
    "# each site\n",
    "for site in site_list:\n",
    "    site_mask = all_best_df['site'] == site\n",
    "    site_df = all_best_df[ site_mask ]\n",
    "    add_trace_site( site_df, site )\n",
    "    \n",
    "# Set title\n",
    "fig_ALL.update_layout(\n",
    "    title_text=\"All sites during the whole time period\"\n",
    ")\n",
    "\n",
    "# Add range slider\n",
    "fig_ALL.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1,\n",
    "                     label=\"1m\",\n",
    "                     step=\"month\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=6,\n",
    "                     label=\"6m\",\n",
    "                     step=\"month\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=1,\n",
    "                     label=\"YTD\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"todate\"),\n",
    "                dict(count=1,\n",
    "                     label=\"1y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_ALL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_mask = all_best_df[\"date_datetime\"].between( datetime.strptime(\"2020-01-01\", \"%Y-%m-%d\"), datetime.strptime(\"2020-01-30\", \"%Y-%m-%d\") )\n",
    "### template: \"plotly\", \"plotly_dark\", \"plotly_white\"\n",
    "\n",
    "fig_ALL2 = px.bar_polar( all_best_df, color=\"Train_R2\", template=\"plotly_dark\", \n",
    "                        theta=\"site\", r=\"Train_R2\",\n",
    "                        color_discrete_sequence= px.colors.sequential.Plasma_r,\n",
    "                       animation_frame=\"date\", range_color=[0,1])\n",
    "\n",
    "fig_ALL2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ALL3 = px.bar_polar( all_best_df_monthly, color=\"Train_R2\", template=\"plotly\", \n",
    "                        theta=\"site\", r=\"Train_R2\",\n",
    "                        color_discrete_sequence= px.colors.sequential.Plasma_r,\n",
    "                       animation_frame=\"month\", range_color=[0,1])\n",
    "\n",
    "fig_ALL3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at each site\n",
    "\n",
    "please replace ``sites_name`` and ```start_date```, ```end_date```\n",
    "\n",
    "---\n",
    "comparision_config, element:\n",
    "\n",
    "- ```HANDS_SITES```\n",
    "- ```NORTH_SITES``` = [ \"keelung\", \"xinying\", \"banqiao\", \"shilin\", \"wanhua\", \"taoyuan\", \"pingzhen\", \"yangming\" ]\n",
    "- ```CHU_MIAO_SITES``` = [ \"zhudong\", \"hsinchu\", \"miaoli\", \"sanyi\" ]\n",
    "- ```CENTRAL_SITES``` = [ \"fengyuan\", \"zhongming\", \"changhua\", \"nantou\" ]\n",
    "- ```YUN_CHIA_NAN_SITES``` = [ \"douliu\", \"puzi\", \"chiayi\", \"xinying\", \"tainan\" ]\n",
    "- ```KAO_PING_SITES``` = [ \"meinong\", \"qianjin\", \"pingtung\", \"hengchun\" ]\n",
    "- ```YILAN_SITES``` = [ \"yilan\" ]\n",
    "- ```HUA_TUNG``` = [ \"taitung\", \"hualien\" ]\n",
    "- ```ISLAND``` = [ \"matsu\", \"kinmen\", \"magong\" ]\n",
    "\n",
    "- ```NEW_SITES``` = [ \"banqiao\", \"taoyuan\", \"zhongming\", \"wanhua\", \"tainan\", \"qianjin\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sites config\n",
    "import comparison_config as config\n",
    "\n",
    "HANDS_SITES = config.HANDS_SITES\n",
    "\n",
    "NORTH_SITES = config.NORTH_SITES\n",
    "CHU_MIAO_SITES = config.CHU_MIAO_SITES\n",
    "CENTRAL_SITES = config.CENTRAL_SITES\n",
    "YUN_CHIA_NAN_SITES = config.YUN_CHIA_NAN_SITES\n",
    "KAO_PING_SITES = config.KAO_PING_SITES\n",
    "YILAN_SITES = config.YILAN_SITES\n",
    "HUA_TUNG = config.HUA_TUNG\n",
    "ISLAND = config.ISLAND\n",
    "\n",
    "NEW_SITES = config.NEW_SITES\n",
    "ALL_SITES = list( HANDS_SITES.keys() )\n",
    "\n",
    "ROW_PATH = \"row_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sites = px.box(ana_df, x=\"day\", y=\"Train_R2\", range_y=[-3, 1.5],\n",
    "                  color=\"method\", notched=True, animation_frame=\"site\")\n",
    "fig_sites.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trace_site2( site, site_df, row_EPA_df, row_AirBox_dfs, cal_df ):\n",
    "    \n",
    "    # Train_R2\n",
    "    fig_site2.add_trace( go.Scatter( x=site_df['date'], y=site_df['Train_R2'], name=site+\"_R2\",\n",
    "                                    line_shape='vh') )\n",
    "    \n",
    "    # row PM2.5\n",
    "    fig_site2.add_trace( go.Scatter( x=row_EPA_df['datetime'], y=row_EPA_df['PM2.5'], name=site+\"_EPA\",\n",
    "                                    line=dict( width=2 )) )\n",
    "    i = 1\n",
    "    for row_AirBox_df in row_AirBox_dfs:\n",
    "        fig_site2.add_trace( go.Scatter( x=row_AirBox_df['datetime'] , y=row_AirBox_df['PM2_5'], \n",
    "                                        name=site+\"_AirBox\"+str(i),\n",
    "                                        line=dict( width=1, dash='dot' ), opacity=0.6) )\n",
    "        i += 1\n",
    "        \n",
    "    # calibration\n",
    "    fig_site2.add_trace( go.Scatter( x=cal_df['datetime'], y=cal_df['PM25_C'], name=site+\"_cal\",\n",
    "                                    line=dict( width=3 )) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_buttons( sites_name ):\n",
    "    \n",
    "    training_v, EPA_PM25_v = [], []\n",
    "    updatemenus=[\n",
    "    dict(\n",
    "        type=\"buttons\",\n",
    "        active=0,\n",
    "        buttons=[]\n",
    "    )]\n",
    "    \n",
    "    total_num = 0\n",
    "    for site in sites_name:\n",
    "        device_num = len(HANDS_SITES[site])\n",
    "        total_num += (device_num + 2)\n",
    "        training_v.extend( [True] + [False]*(device_num+1) )\n",
    "        EPA_PM25_v.extend( [False, True] + [False]*device_num )\n",
    "\n",
    "    #each site\n",
    "    before_num = 0\n",
    "    for site in sites_name:\n",
    "        device_num = len(HANDS_SITES[site])\n",
    "        site_v = [False]*(before_num + 1) + [True]*(device_num + 1) + [False]*( total_num - before_num - device_num -2 )\n",
    "        updatemenus[0][\"buttons\"].append(dict(\n",
    "            label=site,\n",
    "            method=\"update\",\n",
    "            args=[{ \"visible\": site_v }]\n",
    "        ))\n",
    "        \n",
    "        before_num += ( device_num + 2 )\n",
    "    \n",
    "    #training_R2\n",
    "    updatemenus[0][\"buttons\"].append(dict(\n",
    "        label=\"Training R2\",\n",
    "        method=\"update\",\n",
    "        args=[{ \"visible\": training_v }]\n",
    "    ))\n",
    "    \n",
    "    #EPA_PM25\n",
    "    updatemenus[0][\"buttons\"].append(dict(\n",
    "        label=\"EPA PM2.5\",\n",
    "        method=\"update\",\n",
    "        args=[{ \"visible\": EPA_PM25_v }]\n",
    "    ))\n",
    "    \n",
    "    return updatemenus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_site2 = go.Figure()\n",
    "\n",
    "### replace options ###\n",
    "sites_name = CENTRAL_SITES\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2020-02-29\"\n",
    "#######################\n",
    "\n",
    "for site in sites_name:\n",
    "    ROW_devices_df = pd.read_csv( ROW_PATH + site + \".csv\" ).drop( [\"lat\", \"lon\"], axis=1 )\n",
    "    date_mask = ROW_devices_df['datetime'].between( start_date, end_date )\n",
    "    row_devices_df = ROW_devices_df[ date_mask ]\n",
    "    \n",
    "    # free memory\n",
    "    del ROW_devices_df;  gc.collect()\n",
    "    \n",
    "    site_mask = all_best_df['site'] == site\n",
    "    date_mask = all_best_df['date'].between( start_date, end_date )\n",
    "    site_df = all_best_df[ site_mask & date_mask ]\n",
    "    \n",
    "    row_AirBox_dfs = []\n",
    "    for device in HANDS_SITES[site]:\n",
    "        # EPA device\n",
    "        if \"EPA\" in device:\n",
    "            mask = row_devices_df['device_id']==device.replace(\"EPA-\",\"\")\n",
    "            row_EPA_df = row_devices_df[mask].drop( [\"Temperature\", \"Humidity\", \"PM1\"], axis=1 )\n",
    "            row_AirBoxs_df = row_devices_df[~mask]\n",
    "        #AirBox\n",
    "        else:\n",
    "            mask = row_devices_df['device_id']==device\n",
    "            device_df = row_devices_df[mask]\n",
    "            \n",
    "            # hourly\n",
    "            device_df.datetime = pd.to_datetime( device_df.datetime, format=\"%Y-%m-%d %H:%M:%S\" )\n",
    "            device_df['PM2_5'] = device_df['PM2.5'].astype('float')\n",
    "            device_df = device_df.groupby( [\"device_id\", \"datetime\"] ).mean()\n",
    "            level_values = device_df.index.get_level_values\n",
    "            device_df = (device_df.groupby([level_values(i) for i in [0]]\n",
    "                      +[pd.Grouper(freq='1H', level=-1)]).mean())\n",
    "            device_df.reset_index(inplace=True)\n",
    "            \n",
    "            row_AirBox_dfs.append( device_df )\n",
    "            \n",
    "    # AirBoxs mean\n",
    "    row_AirBoxs_df.index = pd.to_datetime( row_AirBoxs_df.datetime, format=\"%Y-%m-%d %H:%M:%S\" )\n",
    "    row_AirBoxs_df['PM2_5'] = row_AirBoxs_df['PM2.5'].astype('float')\n",
    "    hourly_AirBoxs_df = row_AirBoxs_df.resample('1H').mean()\n",
    "    hourly_AirBoxs_df.reset_index( inplace=True )\n",
    "    hourly_AirBoxs_df['date'] = hourly_AirBoxs_df['datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # calibration\n",
    "    hourly_df = pd.merge( hourly_AirBoxs_df, site_df, how='inner', left_on='date', right_on='date' ).drop([\"date_datetime\",\"Train_R2\",\"day\",\"num\",\"RMSE\",\"Test_R2\"],axis=1)\n",
    "    hourly_df['PM25_C'] = hourly_df['PM25']*hourly_df['PM2_5'] + hourly_df['Temperature']*hourly_df['TEM'] + hourly_df['Humidity']*hourly_df['HUM'] + hourly_df[\"datetime\"].dt.hour*hourly_df['HR'] + hourly_df[\"intercept\"]\n",
    "    hourly_df['PM25_C'] = hourly_df['PM25_C'].map( lambda x: 0 if x < 0 else x )\n",
    "    \n",
    "    \n",
    "    add_trace_site2( site, site_df, row_EPA_df, row_AirBox_dfs, hourly_df[ ['datetime', 'PM25_C'] ] )\n",
    "    fig_site2.update_layout( updatemenus = add_buttons( sites_name ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add range slider\n",
    "fig_site2.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "# Set title\n",
    "fig_site2.update_layout(\n",
    "    title_text=\"Detail of each site\",\n",
    "    xaxis_domain=[0, 1.0]\n",
    ")\n",
    "\n",
    "fig_site2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis features\n",
    "\n",
    "please replace ``sites_name`` and ```start_date```, ```end_date```\n",
    "\n",
    "---\n",
    "1. Day\n",
    "2. Feature\n",
    "3. Method\n",
    "4. Time Series\n",
    "5. Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace options ###\n",
    "sites_name = ALL_SITES\n",
    "start_date = \"2019-02-01\"\n",
    "end_date = \"2020-02-29\"\n",
    "#######################\n",
    "\n",
    "site_mask = all_best_df['site'].isin(sites_name)\n",
    "date_mask = all_best_df['date'].between( start_date, end_date )\n",
    "site_df = all_best_df[ site_mask & date_mask ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trace_ana( sites_name, site_df, element, KEY ):\n",
    "    \n",
    "    y_list = []\n",
    "    for site in sites_name:\n",
    "        site_mask = site_df['site'] == site\n",
    "        key_mask = site_df[KEY] == element\n",
    "        \n",
    "        y_list.append( site_df[ site_mask & key_mask ].shape[0] )\n",
    "    \n",
    "    BAR = go.Bar( x=sites_name, y=y_list , name=str(element) )\n",
    "    return BAR, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DAY\n",
    "fig_ana_day = go.Figure()\n",
    "day_dict = {}\n",
    "\n",
    "for day in day_list:\n",
    "    BAR, day_dict[str(day)] = add_trace_ana( sites_name, site_df, day, \"day\" )\n",
    "    fig_ana_day.add_trace( BAR )\n",
    "\n",
    "\n",
    "fig_ana_day.update_layout(barmode='stack', \n",
    "                          xaxis={ 'categoryarray': [x for _, x in sorted(zip(day_dict['7'], sites_name), reverse=True)] }, \n",
    "                          yaxis={ 'categoryarray': day_list, 'categoryorder':'min descending' },\n",
    "                          title_text=\"Day of each site\")\n",
    "fig_ana_day.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature\n",
    "fig_ana_feature = go.Figure()\n",
    "feature_dict = {}\n",
    "\n",
    "for feature in feature_list:\n",
    "    BAR, feature_dict[feature] = add_trace_ana( sites_name, site_df, feature, \"feature\" )\n",
    "    fig_ana_feature.add_trace( BAR )\n",
    "\n",
    "\n",
    "fig_ana_feature.update_layout(barmode='stack', \n",
    "                              xaxis={ 'categoryarray': [x for _, x in sorted(zip(feature_dict['ALL'], sites_name), reverse=True)] }, \n",
    "                              yaxis={ 'categoryarray': feature_list, 'categoryorder':'min descending' },\n",
    "                              title_text=\"Feature of each site\")\n",
    "fig_ana_feature.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method\n",
    "fig_ana_method = go.Figure()\n",
    "method_dict = {}\n",
    "\n",
    "for method in method_list:\n",
    "    BAR, method_dict[method] = add_trace_ana( sites_name, site_df, method, \"method\" )\n",
    "    fig_ana_method.add_trace( BAR )\n",
    "\n",
    "\n",
    "fig_ana_method.update_layout(barmode='stack', \n",
    "                             xaxis={ 'categoryarray': [x for _, x in sorted(zip(method_dict['BayesianRidge'], sites_name), reverse=True)] },\n",
    "                             yaxis={ 'categoryarray': method_list, 'categoryorder':'min descending' },\n",
    "                             title_text=\"Method of each site\")\n",
    "fig_ana_method.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fig_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "### replace options ###\n",
    "sites_name = YUN_CHIA_NAN_SITES\n",
    "start_date = \"2019-02-01\"\n",
    "end_date = \"2020-02-29\"\n",
    "#######################\n",
    "\n",
    "site_mask = all_best_df['site'].isin(sites_name)\n",
    "date_mask = all_best_df['date'].between( start_date, end_date )\n",
    "site_df = all_best_df[ site_mask & date_mask ]\n",
    "\n",
    "# counting \n",
    "ana_df = site_df[ ['Train_R2', 'day', 'feature', 'method', 'site'] ]\n",
    "ana_df = ana_df.groupby( ['site','day','method','feature'] ).aggregate(['count','max','min','mean'])\n",
    "ana_df.reset_index(inplace=True)\n",
    "ana_df[ 'count' ] = ana_df.Train_R2['count']\n",
    "ana_df[ 'mean' ] = ana_df.Train_R2['mean']\n",
    "ana_df[ 'group' ] = ana_df['day'].astype(\"str\").str.cat(ana_df[['feature','method']], sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_percent = make_subplots(1, 2, specs=[[{\"type\": \"domain\"}, {\"type\": \"domain\"}]],)\n",
    "\n",
    "\n",
    "fig_percent = px.sunburst( ana_df, path=['site', 'feature', 'day', 'method'], \n",
    "                          values='count', branchvalues='total',maxdepth=2\n",
    "                     )\n",
    "\n",
    "fig_percent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "Specs = []\n",
    "for e in range(len(sites_name)//2+1):\n",
    "    Specs.append( [{'type':'domain'}, {'type':'domain'}] )\n",
    "fig_pie = make_subplots(rows=len(sites_name)//2+1, cols=2, specs=Specs, subplot_titles=sites_name)\n",
    "\n",
    "\n",
    "i = 2\n",
    "anno = []\n",
    "for site in sites_name:\n",
    "    site_mask=ana_df['site'] == site\n",
    "    site_df = ana_df[ site_mask ].sort_values(['count'],ascending=False).head(10)\n",
    "    fig_pie.add_trace( go.Pie(\n",
    "        labels=site_df['group'], values = site_df['count'], name=site\n",
    "    ), i//2, i%2+1 )\n",
    "    \n",
    "    #anno.append( dict(text=site, x=0.18, y=0.5, font_size=20, showarrow=False) )\n",
    "    i += 1\n",
    "    \n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig_pie.update_traces(hoverinfo=\"label+percent+name\", textposition='inside', textinfo='percent',\n",
    "                     marker=dict(line=dict(color='#000000', width=1)))\n",
    "\n",
    "fig_pie.update_layout(\n",
    "    # Add annotations in the center of the donut pies.\n",
    "    #annotations=anno,\n",
    "    height=300*( len(sites_name)//2+1 ))\n",
    "fig_pie.update( layout_title_text='Fig Pie', layout_showlegend=False )\n",
    "fig_pie.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fig_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace options ###\n",
    "sites_name = YUN_CHIA_NAN_SITES\n",
    "start_date = \"2019-02-01\"\n",
    "end_date = \"2020-02-29\"\n",
    "#######################\n",
    "\n",
    "site_mask = all_best_df['site'].isin(sites_name)\n",
    "date_mask = all_best_df['date'].between( start_date, end_date )\n",
    "site_df = all_best_df[ site_mask & date_mask ][[\"HR\",\"HUM\",\"PM25\",\"TEM\",\"intercept\",\"site\",\"date\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat\n",
    "num_df = pd.DataFrame()\n",
    "for element in [\"HR\",\"HUM\",\"PM25\",\"TEM\"]:\n",
    "    temp_df = site_df[ [element,\"site\",\"date\"] ].rename(columns={element: \"value\"})\n",
    "    temp_df[\"value\"] = temp_df['value'].abs()\n",
    "    temp_df['feature'] = element\n",
    "    num_df = pd.concat( [num_df, temp_df], axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_num = px.scatter(num_df, x=\"date\", y=\"value\", animation_frame=\"site\",\n",
    "           color=\"feature\", hover_name=\"feature\")\n",
    "\n",
    "fig_num.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
